"""
Detailed Log CSV AkÄ±llÄ± Segmentasyon Analizi
- SÃ¼tun kaymalarÄ±nÄ± dÃ¼zeltir
- Training session'larÄ±nÄ± tespit eder (bÃ¼yÃ¼k episode/update reset'leri)
- GeÃ§erli segmentleri belirler
- Ã–zet rapor oluÅŸturur
"""

import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path
from collections import Counter

# Windows encoding sorunu iÃ§in
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')

# Dosya yollarÄ±
if os.path.basename(os.getcwd()) == "scripts":
    BASE_DIR = ".."
elif os.path.basename(os.getcwd()) == "analyses":
    BASE_DIR = ".."
else:
    BASE_DIR = "."

MODELS_DIR = os.path.join(BASE_DIR, "models")
ANALYSES_DIR = os.path.join(BASE_DIR, "analyses")
DETAILED_LOG_FILE = os.path.join(MODELS_DIR, "detailed_log.csv")
OUTPUT_DIR = os.path.join(ANALYSES_DIR, "detailed_log_analysis")

os.makedirs(OUTPUT_DIR, exist_ok=True)

def load_csv_with_fix(file_path):
    """CSV'yi yÃ¼kle ve sÃ¼tun kaymasÄ±nÄ± dÃ¼zelt"""
    print(f"CSV yÃ¼kleniyor: {file_path}")
    
    # Ã–nce ilk birkaÃ§ satÄ±rÄ± oku
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = [f.readline().strip() for _ in range(10)]
    
    header = lines[0]
    print(f"Header: {header}")
    print(f"Header sÃ¼tun sayÄ±sÄ±: {len(header.split(','))}")
    
    # Ä°lk veri satÄ±rlarÄ±nÄ± kontrol et
    data_lines = lines[1:6]
    for i, line in enumerate(data_lines):
        cols = line.split(',')
        print(f"SatÄ±r {i+2} sÃ¼tun sayÄ±sÄ±: {len(cols)} - Ã–rnek: {line[:80]}")
    
    # CSV'yi yÃ¼kle (header'Ä± skip et, manuel oluÅŸtur)
    # Ã–nce tÃ¼m satÄ±rlarÄ± oku
    all_lines = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            all_lines.append(line.strip())
    
    header_line = all_lines[0]
    data_lines = all_lines[1:]
    
    # En yaygÄ±n sÃ¼tun sayÄ±sÄ±nÄ± bul
    col_counts = Counter([len(line.split(',')) for line in data_lines if line.strip()])
    most_common_cols = col_counts.most_common(1)[0][0]
    print(f"\nEn yaygÄ±n sÃ¼tun sayÄ±sÄ±: {most_common_cols}")
    print(f"SÃ¼tun sayÄ±sÄ± daÄŸÄ±lÄ±mÄ±: {dict(col_counts.most_common(5))}")
    
    # Verileri parse et
    parsed_data = []
    for line in data_lines:
        if not line.strip():
            continue
        cols = line.split(',')
        if len(cols) == most_common_cols:
            parsed_data.append(cols)
        elif len(cols) > most_common_cols:
            # Fazla sÃ¼tun varsa, son birkaÃ§Ä±nÄ± birleÅŸtir (virgÃ¼l iÃ§eren string'ler iÃ§in)
            if len(cols) == most_common_cols + 1:
                # Son iki sÃ¼tunu birleÅŸtir (Reason sÃ¼tunu virgÃ¼l iÃ§erebilir)
                cols = cols[:most_common_cols-1] + [','.join(cols[most_common_cols-1:])]
                parsed_data.append(cols)
        else:
            # Eksik sÃ¼tun varsa skip et
            continue
    
    # DataFrame oluÅŸtur
    # Format: Episode,Update,Return,Reason,StartAlt,StartDist,final_dist,final_vel
    if most_common_cols == 8:
        column_names = ['Episode', 'Update', 'Return', 'Reason', 'StartAlt', 'StartDist', 'final_dist', 'final_vel']
    elif most_common_cols == 7:
        column_names = ['Episode', 'Update', 'Return', 'Reason', 'StartAlt', 'StartDist', 'Difficulty']
    else:
        # En yaygÄ±n format'a gÃ¶re tahmin et
        column_names = [f'Col{i+1}' for i in range(most_common_cols)]
    
    df = pd.DataFrame(parsed_data, columns=column_names)
    
    # Veri tiplerini dÃ¼zelt
    df['Episode'] = pd.to_numeric(df['Episode'], errors='coerce')
    df['Update'] = pd.to_numeric(df['Update'], errors='coerce')
    df['Return'] = pd.to_numeric(df['Return'], errors='coerce')
    df['Reason'] = df['Reason'].astype(str).str.strip()
    df['StartAlt'] = pd.to_numeric(df['StartAlt'], errors='coerce')
    df['StartDist'] = pd.to_numeric(df['StartDist'], errors='coerce')
    
    print(f"\nâœ“ CSV yÃ¼klendi: {len(df)} satÄ±r")
    print(f"SÃ¼tunlar: {list(df.columns)}")
    print(f"\nÄ°lk 5 kayÄ±t:")
    print(df.head().to_string())
    
    return df

def find_training_sessions(df, episode_col='Episode', update_col='Update'):
    """Her Episode 1 baÅŸlangÄ±cÄ±nÄ± yeni training session olarak kabul et"""
    print(f"\n{'='*80}")
    print("TRAINING SESSION TESPÄ°TÄ° (Episode 1 = Yeni Session)")
    print(f"{'='*80}")
    
    episodes = df[episode_col].values
    updates = df[update_col].values
    
    # Episode 1'den baÅŸlayan her kayÄ±t â†’ yeni training session
    sessions = []
    
    print(f"\nEpisode 1 baÅŸlangÄ±Ã§larÄ±nÄ± tespit ediliyor...")
    print(f"Ä°lk 20 episode: {episodes[:20].tolist()}")
    
    # Ä°lk satÄ±r her zaman bir session baÅŸlangÄ±cÄ±
    session_starts = [0]
    
    # Episode 1'leri bul (Ã¶nceki episode 1'den farklÄ±ysa veya ilk satÄ±rsa)
    for i in range(1, len(df)):
        ep_prev = episodes[i-1]
        ep_curr = episodes[i]
        
        # Skip NaN deÄŸerler
        if pd.isna(ep_prev) or pd.isna(ep_curr):
            continue
        
        # Episode 1'e dÃ¶nÃ¼ÅŸ varsa ve Ã¶nceki episode 1'den bÃ¼yÃ¼kse â†’ yeni session
        if ep_curr == 1 and ep_prev > 1:
            session_starts.append(i)
    
    print(f"\n{len(session_starts)} training session baÅŸlangÄ±cÄ± bulundu")
    print(f"Ä°lk 10 session baÅŸlangÄ±Ã§ satÄ±rlarÄ±: {session_starts[:10]}")
    
    # Her session'Ä± oluÅŸtur
    for idx, start_idx in enumerate(session_starts):
        # Session bitiÅŸi: bir sonraki session baÅŸlangÄ±cÄ± veya dosya sonu
        end_idx = session_starts[idx + 1] - 1 if idx + 1 < len(session_starts) else len(df) - 1
        
        session = {
            'start_idx': start_idx,
            'end_idx': end_idx,
            'start_episode': int(episodes[start_idx]),
            'end_episode': int(episodes[end_idx]),
            'start_update': int(updates[start_idx]) if not pd.isna(updates[start_idx]) else 0,
            'end_update': int(updates[end_idx]) if not pd.isna(updates[end_idx]) else 0,
            'length': end_idx - start_idx + 1,
            'reason': f"Episode 1 baÅŸlangÄ±cÄ±" if idx == 0 else f"Episode {int(episodes[start_idx-1])} â†’ 1"
        }
        sessions.append(session)
    
    print(f"\nToplam {len(sessions)} training session bulundu:\n")
    print(f"{'#':<4} {'SatÄ±r':<15} {'Episode':<20} {'Update':<20} {'KayÄ±t':<10} {'MaxEp':<8} {'Sebep'}")
    print("-" * 110)
    
    for idx, sess in enumerate(sessions, 1):
        ep_range = f"{int(sess['start_episode'])}-{int(sess['end_episode'])}"
        up_range = f"{int(sess['start_update'])}-{int(sess['end_update'])}"
        row_range = f"{sess['start_idx']}-{sess['end_idx']}"
        max_ep = int(sess['end_episode'])
        print(f"{idx:<4} {row_range:<15} {ep_range:<20} {up_range:<20} {sess['length']:<10} {max_ep:<8} {sess.get('reason', 'Normal')}")
    
    return sessions

def analyze_session_quality(df, sessions):
    """Her session'Ä±n kalitesini analiz et"""
    print(f"\n{'='*80}")
    print("SESSION KALÄ°TE ANALÄ°ZÄ°")
    print(f"{'='*80}\n")
    
    session_stats = []
    
    for idx, sess in enumerate(sessions, 1):
        seg_df = df.iloc[sess['start_idx']:sess['end_idx']+1]
        
        total_eps = len(seg_df)
        success_count = (seg_df['Reason'].str.strip() == 'Success').sum()
        success_rate = (success_count / total_eps * 100) if total_eps > 0 else 0
        
        unique_episodes = seg_df['Episode'].nunique()
        avg_return = seg_df['Return'].mean()
        
        session_stats.append({
            'session': idx,
            'total_episodes': total_eps,
            'unique_episodes': unique_episodes,
            'success_count': success_count,
            'success_rate': success_rate,
            'avg_return': avg_return,
            'start_ep': int(sess['start_episode']),
            'end_ep': int(sess['end_episode']),
            'start_up': int(sess['start_update']),
            'end_up': int(sess['end_update']),
        })
    
    print(f"{'#':<4} {'Toplam':<8} {'Unique':<8} {'Success':<10} {'Success%':<10} {'AvgReturn':<12} {'Episode Range':<20}")
    print("-" * 90)
    
    for stat in session_stats:
        ep_range = f"{stat['start_ep']}-{stat['end_ep']}"
        print(f"{stat['session']:<4} {stat['total_episodes']:<8} {stat['unique_episodes']:<8} "
              f"{stat['success_count']:<10} {stat['success_rate']:<8.1f}% {stat['avg_return']:<12.1f} {ep_range:<20}")
    
    return session_stats

def save_session_files(df, sessions, output_dir):
    """Session'larÄ± ayrÄ± dosyalara kaydet"""
    print(f"\n{'='*80}")
    print("SESSION DOSYALARI OLUÅTURULUYOR")
    print(f"{'='*80}\n")
    
    for idx, sess in enumerate(sessions, 1):
        seg_df = df.iloc[sess['start_idx']:sess['end_idx']+1].copy()
        
        filename = f"session_{idx:02d}_ep{int(sess['start_episode'])}-{int(sess['end_episode'])}_up{int(sess['start_update'])}-{int(sess['end_update'])}.csv"
        filepath = os.path.join(output_dir, filename)
        
        seg_df.to_csv(filepath, index=False, encoding='utf-8')
        print(f"âœ“ Session {idx}: {len(seg_df)} kayÄ±t -> {filename}")
    
    print(f"\nâœ“ TÃ¼m session'lar kaydedildi: {output_dir}")

def main():
    print("="*80)
    print("DETAILED LOG CSV AKILLI SEGMENTASYON ANALÄ°ZÄ°")
    print("="*80)
    print()
    
    # CSV yÃ¼kle
    df = load_csv_with_fix(DETAILED_LOG_FILE)
    
    if df is None or len(df) == 0:
        print("âŒ CSV yÃ¼klenemedi, analiz durduruluyor.")
        return
    
    # Training session'larÄ± bul
    sessions = find_training_sessions(df)
    
    # Session kalitesini analiz et
    session_stats = analyze_session_quality(df, sessions)
    
    # Session dosyalarÄ±nÄ± kaydet
    save_session_files(df, sessions, OUTPUT_DIR)
    
    # Ã–zet rapor
    report_lines = []
    report_lines.append("="*80)
    report_lines.append("DETAILED LOG CSV SEGMENTASYON RAPORU")
    report_lines.append("="*80)
    report_lines.append("")
    report_lines.append(f"Toplam kayÄ±t: {len(df):,}")
    report_lines.append(f"Unique Episode: {df['Episode'].nunique():,}")
    report_lines.append(f"Unique Update: {df['Update'].nunique():,}")
    report_lines.append(f"Episode aralÄ±ÄŸÄ±: {df['Episode'].min():.0f} - {df['Episode'].max():.0f}")
    report_lines.append(f"Update aralÄ±ÄŸÄ±: {df['Update'].min():.0f} - {df['Update'].max():.0f}")
    report_lines.append(f"")
    report_lines.append(f"Training Session sayÄ±sÄ±: {len(sessions)}")
    report_lines.append("")
    report_lines.append("SESSION DETAYLARI:")
    for stat in session_stats:
        report_lines.append(f"  Session {stat['session']}: "
                          f"SatÄ±r {sessions[stat['session']-1]['start_idx']}-{sessions[stat['session']-1]['end_idx']} | "
                          f"Ep {stat['start_ep']}-{stat['end_ep']} | "
                          f"Up {stat['start_up']}-{stat['end_up']} | "
                          f"{stat['total_episodes']} kayÄ±t | "
                          f"Success: {stat['success_rate']:.1f}% | "
                          f"Avg Return: {stat['avg_return']:.1f}")
    
    report_path = os.path.join(OUTPUT_DIR, "segmentation_report.txt")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    
    print(f"\n{'='*80}")
    print("ANALÄ°Z TAMAMLANDI!")
    print(f"{'='*80}")
    print(f"\nğŸ“„ Rapor kaydedildi: {report_path}")
    print(f"ğŸ“ Session dosyalarÄ±: {OUTPUT_DIR}")
    print(f"\nğŸ’¡ Ã–NERÄ°LER:")
    print(f"   1. Session dosyalarÄ±nÄ± inceleyin")
    print(f"   2. Hangileri geÃ§erli eÄŸitim sÃ¼reÃ§leri belirleyin")
    print(f"   3. GeÃ§erli session'larÄ± birleÅŸtirip temiz bir log oluÅŸturun")

if __name__ == "__main__":
    main()
